## monospace杂记

```
文件权限是rw-r--r--，表示文件属主可读可写；文件所属的用户组可读；其他用户可读
```

- 普通文件的文件权限第一个字符为“-”
- 目录文件的文件权限第一个字符为“d”



- **mitmdump --version**

![image-20211117102612394](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20211117102612394.png)



- **mitmweb: No such script**

放到有mitmdump的路径下，再在cmd里切到mitmdump中执行



- **Import [your_module] could not be resolved Pylance**

1. 通过`Shift`+`Ctrl`+`P`打开设置栏，输入`settings`后找到Perference: Open Settings (JSON)

2. 打开settings.json文件后添加下面的代码进去：

   ```python
   "python.analysis.extraPaths": [
       "./src",　　　　　　　　// 自定义模块的相对路径，可多个，可绝对路径　　
       "./modules"
   ]
   ```

   

3. 使用`Ctrl`+`S`保存后，重新打开.py文件，这时自定义的模块就被Pylance找到并导入成功了。



**git submodule update --init**

**需要用git下载，再cd到目录中，在使用git submodule update --init，他可以下载工程里的一些子工程**





**kill 19836** 

杀死 PID 为 19836 的 JobHistoryServer 进程， 默认信号是 15， 正常停止

如果默认信号 15 不能杀死该进程， 则可以尝试使用 信号9， 强制杀死进程 kill -9 19836



**lsof -i :5198** 

列出打开5198端口的进程

与 kill 指令搭配使用



linux 中 ipconfig 是 ip a



set_network -dev eth0 -ip 172.17.10.12 -netmask 255.255.0.0 -dns 172.17.0.1 -gateway 172.17.0.1

service ssh restart

![image-20211119191636728](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20211119191636728.png)

```bash
PS C:\Users\DG> cd .\Downloads\
PS C:\Users\DG\Downloads> scp .\docker_x86_64_21.10.21.02.app.dpk root@172.17.10.12:


root@deepglint:~# ls
AppData  Applications  PKG  SysData  docker_x86_64_21.10.21.02.app.dpk
root@deepglint:~# cd PKG/
root@deepglint:~/PKG# ls
desys.sys.dpk  dfuman.sys.dpk  kernel.partition.dpk  osinfo  rootfs.dpk  uboot.partition.dpk
root@deepglint:~/PKG# mv ../docker_x86_64_21.10.21.02.app.dpk docker_x86_64_21.10.21.02.app.dpk
root@deepglint:~/PKG# ls
desys.sys.dpk   docker_x86_64_21.10.21.02.app.dpk  osinfo      uboot.partition.dpk
dfuman.sys.dpk  kernel.partition.dpk               rootfs.dpk
root@deepglint:~/PKG# cd ..
root@deepglint:~# ls
AppData  Applications  PKG  SysData
root@deepglint:~# cd Applications/
root@deepglint:~/Applications# ls
desys.sys.dpk.mnt  dfuman.sys.dpk.mnt  kernel.partition.dpk.mnt  rootfs.dpk.mnt  uboot.partition.dpk.mnt
# 新建一个目录
root@deepglint:~/Applications# mkdir docker.app.dpk.mnt
root@deepglint:~/Applications# ls
desys.sys.dpk.mnt   docker.app.dpk.mnt        rootfs.dpk.mnt
dfuman.sys.dpk.mnt  kernel.partition.dpk.mnt  uboot.partition.dpk.mnt
root@deepglint:~/Applications# mo
modinfo     modprobe    more        mount       mount.fuse  mount.nfs   mount.nfs4  mountpoint  mountstats
root@deepglint:~/Applications# mount /home/deepglint/PKG/d
desys.sys.dpk                      dfuman.sys.dpk                     docker_x86_64_21.10.21.02.app.dpk
# 挂载两个目录
root@deepglint:~/Applications# mount /home/deepglint/PKG/docker_x86_64_21.10.21.02.app.dpk docker.app.dpk.mnt/
root@deepglint:~/Applications# cd docker.app.dpk.mnt/
root@deepglint:~/Applications/docker.app.dpk.mnt# ls
etc  lib  usr
root@deepglint:~/Applications/docker.app.dpk.mnt# ls -al
total 4
drwxr-xr-x 6 root root   72 Oct 21 15:36 .
drwxrwxr-x 8 root root 4096 Nov 19 19:23 ..
# 隐藏文件夹
drwxrwxrwx 2 root root   41 Oct 21 15:36 .dpk
drwxrwxrwx 3 root root   29 Oct 12 20:43 etc
drwxrwxrwx 3 root root   30 Oct 12 20:43 lib
drwxr-xr-x 4 root root   39 Oct 12 20:26 usr
root@deepglint:~/Applications/docker.app.dpk.mnt# cd .dpk/
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# ls
dpkinfo  run
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# ./run
grep: /home/deepglint/.bash_completion: No such file or directory
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# ./run
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# cd .dpk/^C
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# cat run
#!/bin/bash

data_recovery()
{
    ### recovery data root
    if [ -d /home/deepglint/AppData/docker.app.dpk/var/lib/docker/ ]; then
        mv /home/deepglint/AppData/docker.app.dpk/var/lib/docker/ /home/deepglint/AppData/
    fi

    ### recovery config file
    if [ -e /home/deepglint/AppData/docker.app.dpk/etc/docker/daemon.json ]; then
        cp /home/deepglint/AppData/docker.app.dpk/etc/docker/daemon.json /etc/docker/daemon.json
    fi

    rm -rf /home/deepglint/AppData/docker.app.dpk
}

### data recovery
data_recovery

### create data root
mkdir -p /home/deepglint/AppData/docker

### create config file
if [ ! -e /etc/docker/daemon.json ]; then
        cp /home/deepglint/Applications/docker.app.dpk.mnt/etc/docker/daemon.json /etc/docker/
fi

### bash completion
user_bash_completion=/home/deepglint/.bash_completion
grep -q "^. /home/deepglint/Applications/docker.app.dpk.mnt/usr/share/bash-completion/completions/docker" ${user_bash_completion}
if [ $? -ne 0 ]; then
        echo ". /home/deepglint/Applications/docker.app.dpk.mnt/usr/share/bash-completion/completions/docker" >> ${user_bash_completion}
fi

### start service
cp /home/deepglint/Applications/docker.app.dpk.mnt/lib/systemd/system/app-containerd.service /run/systemd/system/
cp /home/deepglint/Applications/docker.app.dpk.mnt/lib/systemd/system/app-docker.service /run/systemd/system/
cp /home/deepglint/Applications/docker.app.dpk.mnt/lib/systemd/system/app-docker.socket /run/systemd/system/
systemctl daemon-reload
systemctl start app-docker.service
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# cat run ^C
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# history
    1  ls
    2  传递。。
    3  cd ..
    4  ls
    5  cd home/
    6  ls
    7  cd deepglint/
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# ^C
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk# docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
root@deepglint:~/Applications/docker.app.dpk.mnt/.dpk#
```

~/Applications/docker.app.dpk.mnt/.dpk# ./run

##### 端口绑定

在[Linux](https://so.csdn.net/so/search?from=pc_blog_highlight&q=Linux)上普通用户无法绑定1024以下的端口



##### 密码拷贝

ssh-copy-id root@172.17.10.12

打开window的.ssh 然后去远程的.ssh 的authorized_keys中添加



##### 查看Linux网络状况

netstat -tnlp



##### docker启mysql

docker run -dit -p 127.0.0.1:7777:7777 -e MYSQL_ROOT_PASSWARD=root mysql

docker exec -it mysql1 /bin/bash

需要指定一下三个之一：

- MYSQL_ROOT_PASSWORD即root账户的密码。
- MYSQL_ALLOW_EMPTY_PASSWORD即允许密码为空。
- MYSQL_RANDOM_ROOT_PASSWORD随机一个root账户密码。



**tig**

查看当前分支的所有版本



**search**

```
{
    "deviceId": ["lzs5", "wjwtes", "jiawei"],
    "deviceSearch": "AMD64",
    "Online": null,
    "upgradeStatus": null,
    "ErrorCode": null,
    "pageSize": 20,
    "pageNum": 1,
    "order": "id",
    "desc": true,
    "compatibility": ""
}
```



**mysql set**

```mysql
UPDATE aiot_device SET upgrade_status=401 WHERE device_id="wangjiawei7"

select * from aiot_device \G;
use  AIoTCloud;

mycli -u aiotcloud -h 172.17.11.4
password:aiotcloud

delete from aiot_fg_store_migration where version="migration_210916_183050";
 insert into aiot_fg_store_migration (version,created_at) values("migration_210910_140527","2021-11-25 11:18:01.360133275")
```

```go

		// deviceSearch := strings.Split(searchDeviceForm.DeviceSearch, ";")
		// for count, searchString := range deviceSearch {
		// 	if count == 0 {
		// 		query = query.Where("device_id like ? or device_name like ? or device_model like ?",
		// 			"%"+searchString+"%",
		// 			"%"+searchString+"%",
		// 			"%"+searchString+"%")
		// 	} else {
		// 		query = query.Or("device_id like ? or device_name like ? or device_model like ?",
		// 			"%"+searchString+"%",
		// 			"%"+searchString+"%",
		// 			"%"+searchString+"%")
		// 	}
		// }
```

![image-20211125192711624](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20211125192711624.png)



**本地分支重命名** 

git branch -m oldName newName



## regexp中的 OR : |  

功能：可以搜索多个字符串之一，相当于 or

https://blog.csdn.net/qq_39390545/article/details/106414765



``` 
		// if protoVersion&0b000011 == 0 || protoVersion&0b000100 != 0 {
		// 	helper.Error(c, http.StatusBadRequest, helper.NewValidateError("Compatibility", "not support"))
		// 	return
		// } else if protoVersion&0b000010 == 0 {
		// 	query = query.Where("device_model = ?", "")

		// } else if protoVersion&0b000001 == 0 {
		// 	query = query.Where("device_model = ?", "")

		// } else {
		// 	if models, err := config.TxGet(tx.GetTX(c), "model.edge"); err != nil {
		// 		helper.DBError(c, err)
		// 		return
		// 	} else {
		// 		query = query.Where("device_model in (?)", strings.Split(models, ","))
		// 	}
		// }
		query = query.Where("(proto_version & ?) = ?", protoVersion, protoVersion)
```

git stash 将当前改动压栈

git checkout dev 

git pull 获取dev分支的最新代码

git stash pop 将本地的改动弹出来

git pull -p 删除远程多余分支

#### 普通占位符

| 占位符 |              说明              |         举例          |            输出             |
| :----- | :----------------------------: | :-------------------: | :-------------------------: |
| %v     |       相应值的默认格式。       | Printf("%v", people)  |         {zhangsan}          |
| %+v    |   打印结构体时，会添加字段名   | Printf("%+v", people) |       {Name:zhangsan}       |
| %#v    |       相应值的Go语法表示       | Printf("#v", people)  | main.Human{Name:"zhangsan"} |
| %T     |    相应值的类型的Go语法表示    | Printf("%T", people)  |         main.Human          |
| %%     | 字面上的百分号，并非值的占位符 |     Printf("%%")      |              %              |



国家授时中心 NTP 服务器(NTSC NTP Server)

```
ntp.ntsc.ac.cn
```

edge 的数据库文件在home目录下的opt/deepglint/AppData/AIoTEdge/data



/opt/AIoTEdge/data/DOC	

scp AIoTEdge.* wangjiawei@172.17.10.1:

sqlite3 AIoTEdge.db

SELECT * from sqlite_master where type="table";



在自己的home cd .ssh/

```
git reset --hard origin / master
```



更新虚拟机docker 在delinux-CI 选择中间的对应版本 选CI/CD 在选择browser 下载.ios镜像

挂载至光驱 运行delinux 自动安装 手动移除镜像 DXmode -d

delinux docker jobs下载最新的镜像 拷贝到虚拟机 然后在Application新建一个目录 挂载

虚拟机网络设置 set_network -dev eth0 -ip 172.17.10.12 -netmask 255.255.0.0 -dns 172.17.0.1 -gateway 172.17.0.1

set_ssh 打开ssh功能

在虚拟机的SysData创一个devinfo的文件夹 创一个fgdevinfo.conf

DEV_MODEL=AE-AMD64![image-20211230202325547](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20211230202325547.png)



```json
{
    "filer": "http://172.17.11.4:8888/aiotcloud/wjw/image/",
    "image": {
        "deh5_atlas_x86_64_l4ab:21.10.27.02": {
            "url": "fd03208b73ff496899c31a8530807a54",
            "zsyncUrl": "8f0b666b9c074b9abd21fb449e0049a3"
        }
    },
    "deploy": {
        "test": {
            "containers": {
                "deh5": {
                    "image": "deh5_atlas_x86_64_l4ab",
                    "tag": "21.10.27.02"
                },
                "deh6": {
                    "image": "deh5_atlas_x86_64_l4ab",
                    "tag": "21.10.27.02"
                }
            }
        }
    }
}xxxxxxxxxx {    "filer": "http://172.17.11.4:8888/aiotcloud/wjw/image/",    "image": {        "deh5_atlas_x86_64_l4ab:21.10.27.02": {            "url": "fd03208b73ff496899c31a8530807a54",            "zsyncUrl": "8f0b666b9c074b9abd21fb449e0049a3"        }    },    "deploy": {        "test": {            "containers": {                "deh5": {                    "image": "deh5_atlas_x86_64_l4ab",                    "tag": "21.10.27.02"                },                "deh6": {                    "image": "deh5_atlas_x86_64_l4ab",                    "tag": "21.10.27.02"                }            }        }    }}{    "filer": "http://172.17.11.4:8888/aiotcloud/wjw/image/",    "image": {        "cb": {            "url":"1",            "zsyncUrl":"2"        },        "d": {}    },    "deploy": {}}
```



新建远程分支

git push --set-upstream origin feature/request

删除远程分支

git push --delete origin feature/OSApiproxy

删除本地分支

git branch -D feature/request

新建分支

git checkout -b feature/request



常量全大写 都用switch 局部变量小写

跨模块调用 都用common里面的

http://172.17.11.4:8888/aiotcloud/wjw/image/



iotconfig{

​    "server": "tcp://172.17.11.4:1883",

​    "username": "aiotedge",

​    "password": "aiotedge!@#$",

​    "topic": "topic/aiotedge"

}



miss addr 看是不是iot.server



Ubuntu

ssh lizhisheng@172.17.11.4

wxlzs999

cd ../remilia

cd AIoTCloud

docker-compose logs --tail=10 -f web



netstat -tpln

![image-20211221165705284](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20211221165705284.png)



```
package main

import (
	"github.com/spf13/viper"
)

func init() {
	// load config file
	viper.SetEnvPrefix("aiot")
	viper.AutomaticEnv()
	viper.SetConfigName("config")
	viper.AddConfigPath("/data")
	viper.AddConfigPath(".")
	if err := viper.ReadInConfig(); err != nil {
		if _, ok := err.(viper.ConfigFileNotFoundError); !ok {
			panic(err)
		}
	}

	viper.SetDefault("fg.app.name", AppName)
	viper.SetDefault("fg.jwt.expire", 24*60*60)
	viper.SetDefault("fg.jwt.secret", "DeepglintAIoTCloud")
	viper.SetDefault("fg.httpreq.timeout", 60*1000)
	viper.SetDefault("fg.store.table_prefix", "aiot_")
	viper.SetDefault("fg.store.debug", true)
	viper.SetDefault("fg.store.slowsql", 500)
	viper.SetDefault("fg.auth.localUserId", 2)
	viper.SetDefault("fg.auth.localRoleId", 2)

	viper.SetDefault("fg.log.console.enable", true)
	viper.SetDefault("fg.log.console.level", "debug")
	viper.SetDefault("fg.log.rtdebug.enable", false)
	viper.SetDefault("fg.log.rotate.enable", true)
	viper.SetDefault("fg.log.rotate.level", "info")
	viper.SetDefault("fg.log.rotate.file", "./log/AIoTCloud.log")
	viper.SetDefault("fg.log.rotate.maxSize", 8)

	viper.SetDefault("http.type", "tcp")
	viper.SetDefault("http.addr", "0.0.0.0:80")
	viper.SetDefault("http.tls.crt", "")
	viper.SetDefault("http.tls.key", "")

	// common (mysql,redis,filer)
	viper.SetDefault("fg.store.driver", "mysql")
	viper.SetDefault("fg.store.db", "aiotcloud:aiotcloud@tcp(172.17.11.4:3306)/AIoTCloud?charset=utf8mb4&parseTime=True&loc=Local")
	viper.SetDefault("redis.mode", "single")
	viper.SetDefault("redis.server", "172.17.11.4:6379")
	viper.SetDefault("redis.username", "")
	viper.SetDefault("redis.password", "")
	viper.SetDefault("redis.expire", 60*60)
	viper.SetDefault("filer.internal", "http://172.17.11.4:8888/aiotcloud/")
	viper.SetDefault("filer.external", "http://172.17.11.4:8888/aiotcloud/")
	// core (emqx)
	viper.SetDefault("core.mqtt.broker", "tcp://172.17.11.4:1883")
	viper.SetDefault("core.mqtt.adminpass", "Deepglint123")
	viper.SetDefault("core.mqtt.username", "aiotcloud")
	viper.SetDefault("core.mqtt.password", "aiotcloud!@#$")
	viper.SetDefault("core.mqtt.topics", "wjw")
	viper.SetDefault("core.mqtt.banned.interval", 1*60)
	viper.SetDefault("core.mqtt.banned.time", 2*60)
	viper.SetDefault("core.mqtt.banned.counts", 3)
	// cloud
	// ota
	// frp
	viper.SetDefault("frp.enable", false)
	viper.SetDefault("frp.ip", "")
	viper.SetDefault("frp.port", 0)
	viper.SetDefault("frp.token", "")
	viper.SetDefault("frp.dashboard.port", "")
	viper.SetDefault("frp.dashboard.user", 0)
	viper.SetDefault("frp.dashboard.pwd", "")
}

```

func GetDeviceUpgradeStatus(c *gin.Context) {

  deviceId := c.Param("deviceId")



​    if err := redis.UpgradeStatusSet(device.DeviceId, deviceStatus.UpgradeStatus.Data); err != nil {

​      log.Error().Msgf("upgradestatus save to redis failed: %s", err)

​    }

马同学 *https://www.matongxue.com/madocs/7

泰勒展开的一些情况 https://blog.csdn.net/qq_22828175/article/details/83412895

泰勒的一些原理https://blog.csdn.net/qq_38646027/article/details/88014692





```
increase blacklist count 全部count
viper.SetDefault("core.mqtt.bannedinterval", 5*60)
	viper.SetDefault("core.mqtt.bannedtime", 10*60)
	viper.SetDefault("core.mqtt.bannedcounts", 3)
```

```
Consolas, 'Courier New', monospace, Sarasa Mono SC
```



直接cd common/fgweb 然后 git pull --ff

![image-20211217165640925](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20211217165640925.png)

```matlab
a=[1,2,3;4,5,6;7,8,9]
[m,~]=size(a)
fid=fopen('a.txt','w');
for i=1:m
fprintf(fid,'G01 X %d Y %d Z %d\r\n',a(i,:));
end
fclose(fid);
```

```
package model

import "github.com/spf13/viper"

type EdgeConfig struct {
	Filer  string                  `json:"filer"`
	Image  map[string]ImageConfig  `json:"image"`
	Deploy map[string]DeployConfig `json:"deploy"`
}

func NewEdgeConfig() EdgeConfig {
	return EdgeConfig{
		Filer:  viper.GetString("filer.external"),
		Image:  make(map[string]ImageConfig),
		Deploy: make(map[string]DeployConfig),
	}
}

type ImageConfig struct {
	Url      string `json:"url"`
	ZsyncUrl string `json:"zsyncUrl"`
}

type DeployConfig struct {
	Containers map[string]Container `json:"containers"`
}

```

http://172.17.10.7:9100/debug/pprof/goroutine?debug=1

cloud的clientid会带下划线的
edge端是不会带下划线的



$queue/$sys



sysdata devinfo



GOOS=windows make build

到test目录 ./IoTDaemon

file test/IoTDaemon 



git stash -p

![image-20211228130730423](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20211228130730423.png)

http://172.17.11.4:18083/#/websocket

```json
{
    "mode": "raw",
    "autoAddImage": false,
    "containers": {
        "device_id-1-faceDeepGlint": {
            "image": "deh5_atlas_x86_64_l4ab",
            "tag":"21.10.27.02",
            "envs": {
                "ASCEND_VISIBLE_DEVICES": "0",
                "CB_MODE": "face",
                "apiUrl": "http://34.236.0.3:50012/dpccb"
            },
            "mounts": {
                "/etc/localtime": "/etc/localtime",
                "/opt/AIoTEdge/data/atlas00/deepglint-face": "/home/data"
            },
            "priviledged": false
        }
    }
}
```

DEH5CI下载镜像fg.log.console.level debug trace



```json

```

pull后撤销fgweb跟执行git submodule update --init是一样的



用curl结果中包含一些统计信息，使用参数-s去除。-I 只显示消息头

curl http://127.0.0.1:9000/sys/ssh -s

```

```

```

```

htop 查看内存泄漏



CGO_ENABLED=0 go build .



chmod +x main 

./main



go mod init



base64 linux加解码

echo -n 'test' | base64

echo -n dGVzdA== | base64 -d



![image-20220120184150052](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20220120184150052.png)

```go

func (zp *ZsyncProcessor) BindNext(p Processor) {
    cmd := exec.Command("zsyncmake", "-Z")
	zp.w, _ = cmd.StdinPipe()
	zp.r, _ = cmd.StdoutPipe()
	cmd.Stderr = os.Stderr
    
	cmd.Start()
	zp.wg.Add(1)

    go func() {
		buffer := make([]byte, 32*1024)
		for {
			if l, err := zp.r.Read(buffer); err != nil {
				zp.r.Close()
				break
			} else {
				zp.next.Write(buffer[:l])
			}
		}
		if err := cmd.Wait(); err != nil {
			log.Error().Msgf("zsyncmake file error:%s", err)
		}
		zp.wg.Done()
	}()
}
```

172.19.0.2

docker exec -it emqx /bin/bash

![image-20220215153430309](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20220215153430309.png)

172.19.0.3

原始

```
# docker-compose
# sudo curl -L "https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
#
# docker daemon.json
# {"userland-proxy": false}
# or docker-proxy will create 1000+ process
version: "3.9"

services:
  mysql:
    image: mysql:8.0
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - mysql_data:/var/lib/mysql
    environment:
      - MYSQL_RANDOM_ROOT_PASSWORD=true
      - MYSQL_DATABASE=AIoTCloud
      - MYSQL_USER=aiotcloud
      - MYSQL_PASSWORD=aiotcloud
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 5s
      timeout: 20s
      retries: 30

  emqx1:
    image: emqx/emqx:4.3.3
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    ports:
      - 1983:1883 # mqtt
      - 19083:18083 # [debug] dashboard
    environment:
      - EMQX_NAME=emqx1
      - EMQX_HOST=node1.emqx.io
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx1@node1.emqx.io, emqx2@node2.emqx.io
      - EMQX_ADMIN_PASSWORD=Deepglint123
      - EMQX_LOADED_PLUGINS="emqx_management,emqx_dashboard,emqx_auth_redis"
      - EMQX_AUTH__REDIS__TYPE=single
      - EMQX_AUTH__REDIS__SERVER=redis:6379
      - EMQX_AUTH__REDIS__AUTH_CMD=HGET aiot_mqtt_user:%u password
      - EMQX_AUTH__REDIS__SUPER_CMD=HGET aiot_mqtt_user:%u is_superuser
      - EMQX_AUTH__REDIS__ACL_CMD=HGETALL aiot_mqtt_acl:%u
      - EMQX_BROKER__SHARED_SUBSCRIPTION_STRATEGY=hash_clientid
      - EMQX_BROKER__SHARED_DISPATCH_ACK_ENABLED=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - emqx_log:/opt/emqx/log
      - emqx_data:/opt/emqx/data
      - emqx_config:/opt/emqx/etc
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 20s
      retries: 30
    networks:
      emqx-bridge:
        aliases:
        - node1.emqx.io

  emqx2:
    image: emqx/emqx:4.3.3
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - 2083:1883 # mqtt
      - 20083:18083 # [debug] dashboard
    environment:
      - EMQX_NAME=emqx2
      - EMQX_HOST=node2.emqx.io
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx1@node1.emqx.io, emqx2@node2.emqx.io
      - EMQX_ADMIN_PASSWORD=Deepglint123
      - EMQX_LOADED_PLUGINS="emqx_management,emqx_dashboard,emqx_auth_redis"
      - EMQX_AUTH__REDIS__TYPE=single
      - EMQX_AUTH__REDIS__SERVER=redis:6379
      - EMQX_AUTH__REDIS__AUTH_CMD=HGET aiot_mqtt_user:%u password
      - EMQX_AUTH__REDIS__SUPER_CMD=HGET aiot_mqtt_user:%u is_superuser
      - EMQX_AUTH__REDIS__ACL_CMD=HGETALL aiot_mqtt_acl:%u
      - EMQX_BROKER__SHARED_SUBSCRIPTION_STRATEGY=hash_clientid
      - EMQX_BROKER__SHARED_DISPATCH_ACK_ENABLED=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - emqx_log:/opt/emqx/log
      - emqx_data:/opt/emqx/data
      - emqx_config:/opt/emqx/etc
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 20s
      retries: 30
    networks:
      emqx-bridge:
        aliases:
        - node2.emqx.io

  redis:
    image: redis:4.0.14
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - redis_data:/data
    command: redis-server
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 20s
      retries: 30

  weedfs:
    image: chrislusf/seaweedfs:2.64
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - weedfs_data:/data
    command: "server -filer=true -master.volumeSizeLimitMB=16384 -volume.max=1024"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8888"]
      interval: 5s
      timeout: 20s
      retries: 30

  web:
    build: ./web/
    depends_on:
      mysql:
        condition: service_healthy
      emqx1:
        condition: service_healthy
      emqx2:
        condition: service_healthy
      redis:
        condition: service_healthy
      weedfs:
        condition: service_healthy
    restart: always
    ports:
      - 90:80 # web
      - 8000:7000 # frp
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./log:/log
    environment:
      - AIOT_HTTP.ADDR=0.0.0.0:80
      - AIOT_HTTP.TLS.CRT=
      - AIOT_HTTP.TLS.KEY=
      - AIOT_FG.STORE.DRIVER=mysql
      - AIOT_FG.STORE.DB=aiotcloud:aiotcloud@tcp(mysql:3306)/AIoTCloud?charset=utf8mb4&parseTime=True&loc=UTC
      - AIOT_FILER.INTERNAL=http://weedfs:8888/aiotcloud
      - AIOT_FILER.EXTERNAL=http://172.17.0.12:8888/aiotcloud # 外部ip
      - AIOT_REDIS.MODE=single
      - AIOT_REDIS.SERVER=redis:6379
      #- AIOT_core.mqtt.broker=tcp://172.23.0.2:1983,tcp://172.23.0.3:2083
      - AIOT_core.mqtt.broker=tcp://emqx1:1883
      - AIOT_CORE.MQTT.ADMINPASS=Deepglint123
      - AIOT_CORE.MQTT.USERNAME=aiotcloud
      - AIOT_CORE.MQTT.PASSWORD=aiotcloud!@#$$
      #- AIOT_CORE.MQTT.TOPICS=aiotedge,haomuf,haomut,haomul,wjw
      - AIOT_CORE.MQTT.TOPICS=wjw
      - AIOT_OTA.EXTERNAL=http://172.17.0.12:8888 # 外部ip
      - AIOT_FRP.ENABLE=false
      - AIOT_FRP.IP=172.17.0.12
      - AIOT_FRP.PORT=7000
      - AIOT_FRP.TOKEN=be179f2980114d14af30df13ae5c69cb
      - AIOT_FRP.DASHBOARD.PORT=7500
      - AIOT_FRP.DASHBOARD.USER=admin
      - AIOT_FRP.DASHBOARD.PWD=Deepglint123

volumes:
  mysql_data: {}
  redis_data: {}
  emqx_data: {}
  emqx_log: {}
  emqx_config: {}
  weedfs_data: {}

networks:
  emqx-bridge:
    driver: bridge

```

hz的

```
# docker-compose
# sudo curl -L "https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
#
# docker daemon.json
# {"userland-proxy": false}
# or docker-proxy will create 1000+ process
version: "3.9"

services:
  emqx1:
    image: emqx/emqx:4.3.3
    container_name: emqx1
    ports:
      - 1983:1883 # mqtt
      - 19083:18083 # [debug] dashboard
    environment:
      - EMQX_NAME=emqx
      - EMQX_HOST=172.23.0.3
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx@172.23.0.3, emqx@172.23.0.2
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 25s
      retries: 5
    networks:
      emqx-bridge:
        aliases:
        - node1.emqx.io

  emqx2:
    image: emqx/emqx:4.3.3
    container_name: emqx2
    ports:
      - 2083:1883 # mqtt
      - 20083:18083 # [debug] dashboard
    environment:
      - EMQX_NAME=emqx
      - EMQX_HOST=172.23.0.2
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx@172.23.0.3, emqx@172.23.0.2
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 25s
      retries: 5
    networks:
      emqx-bridge:
        aliases:
        - node2.emqx.io

networks:
  emqx-bridge:
    driver: bridge
```

```
# docker-compose
# sudo curl -L "https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
#
# docker daemon.json
# {"userland-proxy": false}
# or docker-proxy will create 1000+ process
version: "3.9"

services:
  mysql:
    image: mysql:8.0
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - mysql_data:/var/lib/mysql
    environment:
      - MYSQL_RANDOM_ROOT_PASSWORD=true
      - MYSQL_DATABASE=AIoTCloud
      - MYSQL_USER=aiotcloud
      - MYSQL_PASSWORD=aiotcloud
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 5s
      timeout: 20s
      retries: 30

  1.emqx.io:
    image: emqx/emqx:4.3.3
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    ports:
      - 3883:1883 # mqtt
      - 38083:18083 # [debug] dashboard
    environment:
      - EMQX_NAME=emqx
      - EMQX_HOST=1.emqx.io
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx@1.emqx.io, emqx@2.emqx.io
      - EMQX_ADMIN_PASSWORD=Deepglint123
      - EMQX_LOADED_PLUGINS="emqx_management,emqx_dashboard,emqx_auth_redis"
      - EMQX_AUTH__REDIS__TYPE=single
      - EMQX_AUTH__REDIS__SERVER=redis:6379
      - EMQX_AUTH__REDIS__AUTH_CMD=HGET aiot_mqtt_user:%u password
      - EMQX_AUTH__REDIS__SUPER_CMD=HGET aiot_mqtt_user:%u is_superuser
      - EMQX_AUTH__REDIS__ACL_CMD=HGETALL aiot_mqtt_acl:%u
      - EMQX_BROKER__SHARED_SUBSCRIPTION_STRATEGY=hash_clientid
      - EMQX_BROKER__SHARED_DISPATCH_ACK_ENABLED=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - emqx1_log:/opt/emqx/log
      - emqx1_data:/opt/emqx/data
      - emqx1_config:/opt/emqx/etc
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 20s
      retries: 30

  2.emqx.io:
    image: emqx/emqx:4.3.3
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - EMQX_NAME=emqx
      - EMQX_HOST=2.emqx.io
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx@1.emqx.io, emqx@2.emqx.io
      - EMQX_ADMIN_PASSWORD=Deepglint123
      - EMQX_LOADED_PLUGINS="emqx_management,emqx_dashboard,emqx_auth_redis"
      - EMQX_AUTH__REDIS__TYPE=single
      - EMQX_AUTH__REDIS__SERVER=redis:6379
      - EMQX_AUTH__REDIS__AUTH_CMD=HGET aiot_mqtt_user:%u password
      - EMQX_AUTH__REDIS__SUPER_CMD=HGET aiot_mqtt_user:%u is_superuser
      - EMQX_AUTH__REDIS__ACL_CMD=HGETALL aiot_mqtt_acl:%u
      - EMQX_BROKER__SHARED_SUBSCRIPTION_STRATEGY=hash_clientid
      - EMQX_BROKER__SHARED_DISPATCH_ACK_ENABLED=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - emqx2_log:/opt/emqx/log
      - emqx2_data:/opt/emqx/data
      - emqx2_config:/opt/emqx/etc
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 20s
      retries: 30

  redis:
    image: redis:4.0.14
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - redis_data:/data
    command: redis-server
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 20s
      retries: 30

  weedfs:
    image: chrislusf/seaweedfs:2.64
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - weedfs_data:/data
    command: "server -filer=true -master.volumeSizeLimitMB=16384 -volume.max=1024"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8888"]
      interval: 5s
      timeout: 20s
      retries: 30

  web:
    build: ./web/
    depends_on:
      mysql:
        condition: service_healthy
      1.emqx.io:
        condition: service_healthy
      2.emqx.io:
        condition: service_healthy
      redis:
        condition: service_healthy
      weedfs:
        condition: service_healthy
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./log:/log
    environment:
      - AIOT_HTTP.ADDR=0.0.0.0:80
      - AIOT_HTTP.TLS.CRT=
      - AIOT_HTTP.TLS.KEY=
      - AIOT_FG.STORE.DRIVER=mysql
      - AIOT_FG.STORE.DB=aiotcloud:aiotcloud@tcp(mysql:3306)/AIoTCloud?charset=utf8mb4&parseTime=True&loc=UTC
      - AIOT_FILER.INTERNAL=http://weedfs:8888/aiotcloud
      - AIOT_FILER.EXTERNAL=http://172.17.0.12:8888/aiotcloud # 外部ip
      - AIOT_REDIS.MODE=single
      - AIOT_REDIS.SERVER=redis:6379
      #- AIOT_core.mqtt.broker=tcp://172.23.0.2:1983,tcp://172.23.0.3:2083
      - AIOT_core.mqtt.broker=tcp://1.emqx.io:1883
      - AIOT_CORE.MQTT.ADMINPASS=Deepglint123
      - AIOT_CORE.MQTT.USERNAME=aiotcloud
      - AIOT_CORE.MQTT.PASSWORD=aiotcloud!@#$$
      #- AIOT_CORE.MQTT.TOPICS=aiotedge,haomuf,haomut,haomul,wjw
      - AIOT_CORE.MQTT.TOPICS=wjw
      - AIOT_OTA.EXTERNAL=http://172.17.0.12:8888 # 外部ip
      - AIOT_FRP.ENABLE=false
      - AIOT_FRP.IP=172.17.0.12
      - AIOT_FRP.PORT=7000
      - AIOT_FRP.TOKEN=be179f2980114d14af30df13ae5c69cb
      - AIOT_FRP.DASHBOARD.PORT=7500
      - AIOT_FRP.DASHBOARD.USER=admin
      - AIOT_FRP.DASHBOARD.PWD=Deepglint123

volumes:
  mysql_data: {}
  redis_data: {}
  emqx1_data: {}
  emqx1_log: {}
  emqx1_config: {}
  emqx2_data: {}
  emqx2_log: {}
  emqx2_config: {}
  weedfs_data: {}

```

ok的

```json
# docker-compose
# sudo curl -L "https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
#
# docker daemon.json
# {"userland-proxy": false}
# or docker-proxy will create 1000+ process
version: "3.9"

services:
  mysql:
    image: mysql:8.0
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - mysql_data:/var/lib/mysql
    environment:
      - MYSQL_RANDOM_ROOT_PASSWORD=true
      - MYSQL_DATABASE=AIoTCloud
      - MYSQL_USER=aiotcloud
      - MYSQL_PASSWORD=aiotcloud
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 5s
      timeout: 20s
      retries: 30

  1.emqx.io:
    image: emqx/emqx:4.3.3
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    ports:
      - 3883:1883 # mqtt
      - 38083:18083 # [debug] dashboard
    environment:
      - EMQX_NAME=emqx
      - EMQX_HOST=1.emqx.io
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx@1.emqx.io, emqx@2.emqx.io
      - EMQX_ADMIN_PASSWORD=Deepglint123
      - EMQX_LOADED_PLUGINS="emqx_management,emqx_dashboard,emqx_auth_redis"
      - EMQX_AUTH__REDIS__TYPE=single
      - EMQX_AUTH__REDIS__SERVER=redis:6379
      - EMQX_AUTH__REDIS__AUTH_CMD=HGET aiot_mqtt_user:%u password
      - EMQX_AUTH__REDIS__SUPER_CMD=HGET aiot_mqtt_user:%u is_superuser
      - EMQX_AUTH__REDIS__ACL_CMD=HGETALL aiot_mqtt_acl:%u
      - EMQX_BROKER__SHARED_SUBSCRIPTION_STRATEGY=hash_clientid
      - EMQX_BROKER__SHARED_DISPATCH_ACK_ENABLED=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - emqx1_log:/opt/emqx/log
      - emqx1_data:/opt/emqx/data
      - emqx1_config:/opt/emqx/etc
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 20s
      retries: 30

  2.emqx.io:
    image: emqx/emqx:4.3.3
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    ports:
      - 4883:1883 # mqtt
      - 48083:18083 # [debug] dashboard
    environment:
      - EMQX_NAME=emqx
      - EMQX_HOST=2.emqx.io
      - EMQX_CLUSTER__DISCOVERY=static
      - EMQX_CLUSTER__STATIC__SEEDS=emqx@1.emqx.io, emqx@2.emqx.io
      - EMQX_ADMIN_PASSWORD=Deepglint123
      - EMQX_LOADED_PLUGINS="emqx_management,emqx_dashboard,emqx_auth_redis"
      - EMQX_AUTH__REDIS__TYPE=single
      - EMQX_AUTH__REDIS__SERVER=redis:6379
      - EMQX_AUTH__REDIS__AUTH_CMD=HGET aiot_mqtt_user:%u password
      - EMQX_AUTH__REDIS__SUPER_CMD=HGET aiot_mqtt_user:%u is_superuser
      - EMQX_AUTH__REDIS__ACL_CMD=HGETALL aiot_mqtt_acl:%u
      - EMQX_BROKER__SHARED_SUBSCRIPTION_STRATEGY=hash_clientid
      - EMQX_BROKER__SHARED_DISPATCH_ACK_ENABLED=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - emqx2_log:/opt/emqx/log
      - emqx2_data:/opt/emqx/data
      - emqx2_config:/opt/emqx/etc
    healthcheck:
      test: ["CMD", "/opt/emqx/bin/emqx_ctl", "status"]
      interval: 5s
      timeout: 20s
      retries: 30

  redis:
    image: redis:4.0.14
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - redis_data:/data
    command: redis-server
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 20s
      retries: 30

  weedfs:
    image: chrislusf/seaweedfs:2.64
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - weedfs_data:/data
    command: "server -filer=true -master.volumeSizeLimitMB=16384 -volume.max=1024"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8888"]
      interval: 5s
      timeout: 20s
      retries: 30

  web:
    build: ./web/
    depends_on:
      mysql:
        condition: service_healthy
      1.emqx.io:
        condition: service_healthy
      2.emqx.io:
        condition: service_healthy
      redis:
        condition: service_healthy
      weedfs:
        condition: service_healthy
    restart: always
    ports:
      - 90:80 # web
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./log:/log
    environment:
      - AIOT_HTTP.ADDR=0.0.0.0:80
      - AIOT_HTTP.TLS.CRT=
      - AIOT_HTTP.TLS.KEY=
      - AIOT_FG.STORE.DRIVER=mysql
      - AIOT_FG.STORE.DB=aiotcloud:aiotcloud@tcp(mysql:3306)/AIoTCloud?charset=utf8mb4&parseTime=True&loc=UTC
      - AIOT_FILER.INTERNAL=http://weedfs:8888/aiotcloud
      - AIOT_FILER.EXTERNAL=http://172.17.0.12:8888/aiotcloud # 外部ip
      - AIOT_REDIS.MODE=single
      - AIOT_REDIS.SERVER=redis:6379
      #- AIOT_core.mqtt.brokers=tcp://172.23.0.2:1983,tcp://172.23.0.3:2083
      - AIOT_CORE.MQTT.BROKER=tcp://1.emqx.io:1883,tcp://2.emqx.io:1883
      - AIOT_CORE.MQTT.ADMINPASS=Deepglint123
      - AIOT_CORE.MQTT.USERNAME=aiotcloud
      - AIOT_CORE.MQTT.PASSWORD=aiotcloud!@#$$
      #- AIOT_CORE.MQTT.TOPICS=aiotedge,haomuf,haomut,haomul,wjw
      - AIOT_CORE.MQTT.TOPICS=wjw
      - AIOT_OTA.EXTERNAL=http://172.17.0.12:8888 # 外部ip
      - AIOT_FRP.ENABLE=false
      - AIOT_FRP.IP=172.17.0.12
      - AIOT_FRP.PORT=7000
      - AIOT_FRP.TOKEN=be179f2980114d14af30df13ae5c69cb
      - AIOT_FRP.DASHBOARD.PORT=7500
      - AIOT_FRP.DASHBOARD.USER=admin
      - AIOT_FRP.DASHBOARD.PWD=Deepglint123

volumes:
  mysql_data: {}
  redis_data: {}
  emqx1_data: {}
  emqx1_log: {}
  emqx1_config: {}
  emqx2_data: {}
  emqx2_log: {}
  emqx2_config: {}
  weedfs_data: {}

```







![image-20220217191401302](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20220217191401302.png)

![image-20220218173349980](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20220218173349980.png)

删除指定容器docker rm -f $(docker ps -a | grep 'wangjiawei'| awk '{print $1 }')

![image-20220221122923250](C:\Users\DG\AppData\Roaming\Typora\typora-user-images\image-20220221122923250.png)

给成都升级iot：将新的AIoTCloud与docker-compose.yaml拷贝到本地scp wangjiawei@172.17.11.4:/home/remilia/AIoTCloud/web/AIoTCloud ./

连vpn，登陆http://172.27.15.98:8080/core/auth/login/账号lvtao密码LTcftygv123，拷贝过去

登录跳板机lvtao@172.27.15.98 -p 2222 选server5 重新编译docker-compose.yaml，新的web服务部署再172.27.15.75上

VPN
模式： l2tp

域名：118.114.77.3
账号：cdyttest
密码：admin@123!
共享密码：Abc.123@#$

跳板机 172.27.15.98
用户名 lvtao  端口2222  密码 LTcftygv123
就部署在 172.27.15.75上

aiotedge: systemctl start app-aiotedge.service

不影响功能的 用warn就好

cat

【一】从第3000行开始，显示1000行。即显示3000~3999行

cat filename | tail -n +3000 | head -n 1000

【二】显示1000行到3000行

cat filename| head -n 3000 | tail -n +1000

*注意两种方法的顺序

  tail -n 1000：显示最后1000行

  tail -n +1000：从1000行开始显示，显示1000行以后的

  head -n 1000：显示前面1000行

busctl call com.deepglint.delinux.dfumand /com/deepglint/delinux/dfumand com.deepglint.delinux.dfumand Trigger "s" "{\"url\":\"http://172.17.10.1:12377\",\"token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NDc0MDAzOTUsImlhdCI6MTY0NzMxMzk5NSwibmJmIjoxNjQ3MzEzOTk1LCJzdWIiOiIyLDIifQ.Zb56_dA9D10ZD30CO6bUcb6CvmvoOiubfr3PClP6Ut8\"}"



计算文件md5 拷贝到10.1 用md5sum 文件名 计算

